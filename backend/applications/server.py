from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from typing import Optional, List, Dict, Any
import polars as pl
import joblib
import json
import sys
import os
import asyncio
import requests
import numpy as np
import subprocess
import threading
from contextlib import asynccontextmanager
import nflreadpy as nfl
from dotenv import load_dotenv
from apscheduler.schedulers.background import BackgroundScheduler
from datetime import datetime

# --- 1. CONFIGURATION ---
load_dotenv()
DB_CONNECTION_STRING = os.getenv("DB_CONNECTION_STRING")
if not DB_CONNECTION_STRING:    
    sys.exit("Error: DB_CONNECTION_STRING not found.")

current_dir = os.path.dirname(os.path.abspath(__file__))
PROJECT_ROOT = os.path.abspath(os.path.join(current_dir, '..'))
dataPrep_dir = os.path.abspath(os.path.join(current_dir, '..', 'dataPrep'))
RAG_DIR = os.path.join(PROJECT_ROOT, 'rag_data')
MODEL_DIR = os.path.join(PROJECT_ROOT, 'model_training', 'models')

# Correctly locate the ETL script
ETL_SCRIPT_PATH = os.path.abspath(os.path.join(current_dir, '..', 'rag_data', '05_etl_to_postgres.py'))

if dataPrep_dir not in sys.path: sys.path.insert(0, dataPrep_dir)

try:
    from feature_generator_timeseries import generate_features_all
except ImportError:
    print("Warning: feature_generator_timeseries not found.")

# --- 2. CONSTANTS ---
CURRENT_SEASON = 2025
MAE_VALUES = {'QB': 4.30, 'RB': 5.19, 'WR': 4.33, 'TE': 4.34}
META_MAE_VALUES = {'QB': 4.79, 'RB': 3.66, 'WR': 2.88, 'TE': 2.41}
WATCHLIST_FILE = os.path.join(RAG_DIR, 'watchlist.json')

MODELS_CONFIG = {
    'QB': {'model': os.path.join(MODEL_DIR, 'xgboost_QB_sliding_window_v1(TimeSeries).joblib'), 'features': os.path.join(MODEL_DIR, 'feature_names_QB_sliding_window_v1(TimeSeries).json')},
    'RB': {'model': os.path.join(MODEL_DIR, 'xgboost_RB_sliding_window_v1(TimeSeries).joblib'), 'features': os.path.join(MODEL_DIR, 'feature_names_RB_sliding_window_v1(TimeSeries).json')},
    'WR': {'model': os.path.join(MODEL_DIR, 'xgboost_WR_sliding_window_v1(TimeSeries).joblib'), 'features': os.path.join(MODEL_DIR, 'feature_names_WR_sliding_window_v1(TimeSeries).json')},
    'TE': {'model': os.path.join(MODEL_DIR, 'xgboost_TE_sliding_window_v1(TimeSeries).joblib'), 'features': os.path.join(MODEL_DIR, 'feature_names_TE_sliding_window_v1(TimeSeries).json')}
}
META_MODEL_PATH = os.path.join(MODEL_DIR, 'xgboost_META_model_v1.joblib')
META_FEATURES_PATH = os.path.join(MODEL_DIR, 'feature_names_META_model_v1.json')

model_data = {}

# --- HELPER: Refresh Database Data (Crucial for Startup) ---
def refresh_db_data():
    """Reloads all dataframes from Postgres. Runs ONCE at startup and after ETL."""
    print("üîÑ [System] Loading Dataframes from Database...")
    queries = {
        "df_profile": "SELECT * FROM player_profiles",
        "df_schedule": "SELECT * FROM schedule",
        "df_player_stats": "SELECT * FROM weekly_player_stats",
        "df_snap_counts": "SELECT * FROM weekly_snap_counts",
        "df_odds": "SELECT * FROM weekly_player_odds",
        "df_defense": "SELECT * FROM weekly_defense_stats",
        "df_offense": "SELECT * FROM weekly_offense_stats",
        "df_overunder": "SELECT * FROM schedule",
        "df_injuries": "SELECT * FROM weekly_injuries",       
        "df_game_spreads": "SELECT week, home_team, away_team, over_under FROM schedule WHERE over_under IS NOT NULL"
    }
    
    for key, query in queries.items():
        try:
            model_data[key] = pl.read_database_uri(query, DB_CONNECTION_STRING)
        except Exception as e:
            print(f"‚ö†Ô∏è {key} load failed: {e}")
            model_data[key] = pl.DataFrame()

    # DEBUG: Check loaded schedule weeks to ensure Week 16 exists
    try:
        if not model_data["df_schedule"].is_empty():
            weeks = sorted(model_data["df_schedule"]["week"].unique().to_list())
            print(f"‚úÖ Schedule Loaded: Weeks {weeks[:1]}...{weeks[-1:]} (Total {len(weeks)} games)")
        else:
            print("‚ö†Ô∏è Schedule DataFrame is EMPTY!")
    except: pass

    # Re-build Injury Map
    try:
        if "df_injuries" in model_data and not model_data["df_injuries"].is_empty():
            inj = model_data["df_injuries"].select(['gsis_id', 'report_status']).drop_nulls()
            model_data["injury_map"] = dict(zip(inj['gsis_id'], inj['report_status']))
        else:
            model_data["injury_map"] = {}
    except:
        model_data["injury_map"] = {}
    
    print("‚úÖ [System] Database Refresh Complete.")

# --- HELPER: Refresh State (Week & IDs) ---
def refresh_app_state():
    """Updates the dynamic variables like Current Week and ID Maps."""
    print("üîÑ [Scheduler] Refreshing App State (Week & IDs)...")
    
    # 1. Update Week
    try:
        base_week = nfl.get_current_week()
        
        # --- TUESDAY LOGIC ---
        if datetime.now().weekday() == 1: 
            print(f"üìÖ Tuesday Detected: Advancing Week from {base_week} to {base_week + 1}")
            model_data["current_nfl_week"] = base_week + 1
        else:
            model_data["current_nfl_week"] = base_week
            
        print(f"‚úÖ Active NFL Week: {model_data['current_nfl_week']}")
    except Exception as e:
        print(f"‚ö†Ô∏è Failed to detect week: {e}")
        if "current_nfl_week" not in model_data:
            model_data["current_nfl_week"] = 1

    # 2. Update ID Map
    print("üì• Downloading/Refreshing Player ID Map...")
    try:
        players_df = nfl.load_ff_playerids()
        if "sleeper_id" in players_df.columns and "gsis_id" in players_df.columns:
            map_df = players_df.drop_nulls(subset=['sleeper_id', 'gsis_id'])
            sleeper_ids = map_df['sleeper_id'].cast(pl.Utf8).to_list()
            gsis_ids = map_df['gsis_id'].to_list()
            
            model_data["sleeper_map"] = dict(zip(sleeper_ids, gsis_ids))
            print(f"‚úÖ ID Map Ready ({len(model_data['sleeper_map'])} players mapped)")
        else:
            print("‚ö†Ô∏è ID Map columns missing.")
    except Exception as e:
        print(f"‚ö†Ô∏è ID Map Download Failed: {e}")
        if "sleeper_map" not in model_data:
            model_data["sleeper_map"] = {}

# --- ETL Runner Function ---
def run_daily_etl():
    """Runs the 05_etl_to_postgres.py script as a subprocess."""
    print("\n‚è∞ [Scheduler] Starting Daily ETL Pipeline...")
    
    if not os.path.exists(ETL_SCRIPT_PATH):
        print(f"‚ùå [Scheduler] ETL Script not found at: {ETL_SCRIPT_PATH}")
        return

    try:
        # Run script using current Python interpreter
        # FIX: Added encoding='utf-8' to handle emojis like üöÄ on Windows
        result = subprocess.run(
            [sys.executable, ETL_SCRIPT_PATH], 
            capture_output=True, 
            text=True, 
            encoding='utf-8' 
        )
        
        if result.returncode == 0:
            print("‚úÖ [Scheduler] Daily ETL Finished Successfully.")
            # Safe print: check if stdout exists before slicing
            if result.stdout:
                print(result.stdout[-300:]) 
            
            # --- CRITICAL: Refresh Data AFTER ETL finishes ---
            refresh_app_state()
            refresh_db_data()
        else:
            print(f"‚ùå [Scheduler] ETL Failed with code {result.returncode}")
            if result.stderr:
                print(result.stderr)
            
    except Exception as e:
        print(f"‚ùå [Scheduler] Exception running ETL: {e}")

# --- 3. LIFESPAN ---
@asynccontextmanager
async def lifespan(app: FastAPI):
    print("--- üöÄ Server Startup Sequence ---")
    
    try:
        # 1. Load Static Models
        print("1Ô∏è‚É£  Loading ML Models...")
        model_data["models"] = {}
        for pos, paths in MODELS_CONFIG.items():
            if os.path.exists(paths['model']):
                model_data["models"][pos] = {
                    "model": joblib.load(paths['model']),
                    "features": json.load(open(paths['features']))
                }
        
        if os.path.exists(META_MODEL_PATH):
            model_data["meta_models"] = joblib.load(META_MODEL_PATH)
            model_data["meta_features"] = json.load(open(META_FEATURES_PATH))

        # 2. Get Week & IDs
        print("2Ô∏è‚É£  Detecting Week & IDs...")
        refresh_app_state()

        # 3. Load DB Data (BLOCKING) - Ensures schedule exists before server starts
        print("3Ô∏è‚É£  Loading Database Data (Wait for it)...")
        refresh_db_data()

    except Exception as e:
        print(f"‚ùå Startup Error: {e}")
        sys.exit(1)

    # --- A. SETUP SCHEDULER ---
    scheduler = BackgroundScheduler()
    # Run ETL every day at 5:00 AM
    scheduler.add_job(run_daily_etl, 'cron', hour=5, minute=0)
    # Refresh Week/IDs every hour
    scheduler.add_job(refresh_app_state, 'interval', hours=1)
    scheduler.start()
    print("üïí Scheduler started.")

    # --- B. RUN BACKGROUND ETL ---
    # Now that we have loaded the "old" data, we can start the ETL refresh in the background
    print("‚ö° Triggering Background ETL Update...")
    startup_etl_thread = threading.Thread(target=run_daily_etl)
    startup_etl_thread.start()
    
    print("üöÄ Server Ready to Accept Requests!")
    yield
    
    scheduler.shutdown()
    model_data.clear()

app = FastAPI(lifespan=lifespan)
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# --- 4. CORE LOGIC ---

def get_headshot_url(player_id: str):
    try:
        row = model_data["df_profile"].filter(pl.col("player_id") == player_id)
        if not row.is_empty():
            db_url = row.row(0, named=True).get("headshot")
            if db_url: return db_url
    except: pass
    return f"https://sleepercdn.com/content/nfl/players/{player_id}.jpg"

def format_draft_info(year, number):
    if year and number and not np.isnan(number):
        return f"Pick {int(number)} ({int(year)})"
    return "Undrafted"

def calculate_fantasy_points(row):
    try:
        if row.get('y_fantasy_points_ppr') is not None: return float(row['y_fantasy_points_ppr'])
        if row.get('fantasy_points_ppr') is not None: return float(row['fantasy_points_ppr'])
        if row.get('fantasy_points') is not None: return float(row['fantasy_points'])
        
        p_yds = row.get('passing_yards') or row.get('pass_yds') or 0
        p_tds = row.get('passing_tds') or 0
        r_yds = row.get('rushing_yards') or row.get('rush_yds') or 0
        r_tds = row.get('rushing_tds') or 0
        rec_yds = row.get('receiving_yards') or row.get('rec_yds') or 0
        rec_tds = row.get('receiving_tds') or 0
        receptions = row.get('receptions') or 0
        ints = row.get('interceptions') or 0
        fumbles = row.get('fumbles_lost') or 0
        
        return (
            (p_yds * 0.04) + (p_tds * 4.0) + (r_yds * 0.1) + (r_tds * 6.0) + 
            (rec_yds * 0.1) + (rec_tds * 6.0) + (receptions * 1.0) - 
            (ints * 2.0) - (fumbles * 2.0)
        )
    except: return 0.0

def run_base_prediction(pid, pos, week):
    features, err = generate_features_all(
        pid, week, model_data["df_profile"], model_data["df_schedule"],
        model_data["df_player_stats"], model_data["df_defense"],
        model_data["df_offense"], model_data["df_snap_counts"]
    )
    if not features: return None, err, None
    
    if pos not in model_data["models"]: return None, "No Model", None
    m_info = model_data["models"][pos]
    feats = {k: [features.get(k, 0.0)] for k in m_info["features"]}
    pred = m_info["model"].predict(pl.DataFrame(feats).to_numpy())[0]
    return float(pred), None, features

async def get_player_card(player_id: str, week: int):
    profile = model_data["df_profile"].filter(pl.col('player_id') == player_id)
    if profile.is_empty(): return None
    p_row = profile.row(0, named=True)
    pos, team = p_row['position'], p_row['team_abbr']

    l0_score, err, feats = run_base_prediction(player_id, pos, week)
    if err: l0_score = 0.0

    try:
        teammates = {'QB': 0.0, 'RB': 0.0, 'WR': 0.0, 'TE': 0.0}
        teammates[pos] = l0_score or 0.0
        roster = model_data["df_profile"].filter((pl.col('team_abbr') == team) & (pl.col('status') == 'ACT') & (pl.col('player_id') != player_id))
        for p_pos in ['QB', 'RB', 'WR', 'TE']:
            if p_pos == pos: continue
            mate = roster.filter(pl.col('position') == p_pos).head(1)
            if not mate.is_empty():
                m_id = mate.row(0, named=True)['player_id']
                s, _, _ = run_base_prediction(m_id, p_pos, week)
                if s: teammates[p_pos] = s

        if pos == 'QB': meta_score = l0_score
        elif pos in model_data["meta_models"]:
            meta_in = {f"L0_pred_{k}": [v] for k, v in teammates.items()}
            meta_input = pl.DataFrame(meta_in).select(model_data["meta_features"]).to_numpy()
            meta_score = float(model_data["meta_models"][pos].predict(meta_input)[0])
        else: meta_score = l0_score 
    except: meta_score = l0_score 
    
    mae = META_MAE_VALUES.get(pos, 5.0)
    
    avg_points = 0.0
    try:
        stats_history = model_data['df_player_stats'].filter((pl.col('player_id') == player_id) & (pl.col('week') < week))
        if not stats_history.is_empty():
            total_points, game_count = 0.0, 0
            for row in stats_history.iter_rows(named=True):
                pts = calculate_fantasy_points(row)
                if pts > 0 or row.get('offense_snaps', 0) > 0:
                    total_points += pts
                    game_count += 1
            if game_count > 0: avg_points = total_points / game_count
    except: pass

    snap_count, snap_pct = 0, 0.0
    try:
        # Try current week first
        row = model_data["df_snap_counts"].filter((pl.col("player_id") == player_id) & (pl.col("week") == week))
        if not row.is_empty(): 
            d = row.row(0, named=True)
            snap_count, snap_pct = int(d.get("offense_snaps", 0)), float(d.get("offense_pct", 0.0))
        else:
            # FALLBACK: Get average from previous weeks if current week is missing
            hist_rows = model_data["df_snap_counts"].filter(pl.col("player_id") == player_id)
            if not hist_rows.is_empty():
                avg_pct = hist_rows["offense_pct"].mean()
                snap_pct = float(avg_pct) if avg_pct else 0.0
    except: pass

    # --- OVER/UNDER LOGIC ---
    total_line = None
    try:
        spread_df = model_data["df_game_spreads"].filter(pl.col("week") == week)
        game_row = spread_df.filter((pl.col("home_team") == team) | (pl.col("away_team") == team))
        if not game_row.is_empty():
            total_line = game_row.row(0, named=True).get("over_under")
            if total_line is not None: total_line = float(total_line)
    except Exception as e:
        print(f"Over/Under lookup error: {e}")
        total_line = None
    
    opponent = "BYE"
    try:
        game = model_data["df_schedule"].filter((pl.col("week") == week) & ((pl.col("home_team") == team) | (pl.col("away_team") == team)))
        if not game.is_empty(): row = game.row(0, named=True); opponent = row['away_team'] if row['home_team'] == team else row['home_team']
    except: pass

    injury_status = model_data.get("injury_map", {}).get(player_id, "Active")

    return {
        "player_name": p_row['player_name'],
        "player_id": player_id,
        "position": pos,
        "week": week,
        "team": team,
        "opponent": opponent,
        "draft_position": format_draft_info(p_row.get('draft_year'), p_row.get('draft_number')),
        "snap_count": snap_count,
        "snap_percentage": snap_pct,
        "overunder": total_line,
        "spread": total_line,
        "image": get_headshot_url(player_id),
        "prediction": round(meta_score + mae, 2),  
        "floor_prediction": round(meta_score, 2),
        "average_points": round(avg_points, 1),
        "injury_status": injury_status
    }

async def get_team_roster_cards(team_abbr: str, week: int):
    composition = {"QB": 5, "RB": 5, "WR": 5, "TE": 5}
    roster_result = []
    try:
        q = f"SELECT player_id, position FROM weekly_rankings WHERE week={week} AND team_abbr='{team_abbr}' ORDER BY predicted_points DESC"
        ranked = pl.read_database_uri(q, DB_CONNECTION_STRING)
    except: ranked = pl.DataFrame()
    if ranked.is_empty():
        ranked = model_data["df_profile"].filter((pl.col("team_abbr") == team_abbr) & (pl.col("status") == "ACT")).select(["player_id", "position"])
    for pos, limit in composition.items():
        candidates = ranked.filter(pl.col("position") == pos).head(limit)
        for row in candidates.iter_rows(named=True):
            card = await get_player_card(row['player_id'], week)
            if card: roster_result.append(card)
    order = {"QB": 1, "RB": 2, "WR": 3, "TE": 4}
    roster_result.sort(key=lambda x: order.get(x["position"], 99))
    return roster_result

async def fetch_sleeper_trends(trend_type: str, limit: int = 10, week: int = 1):
    if not model_data.get("sleeper_map"):
        refresh_app_state() # Use new refresh function if map missing

    try:
        url = f"https://api.sleeper.app/v1/players/nfl/trending/{trend_type}?lookback_hours=24&limit={limit+10}"
        headers = {"User-Agent": "Mozilla/5.0"}
        
        response = requests.get(url, headers=headers, timeout=3)
        if response.status_code != 200: return []
        
        data = response.json()
        
        cards = []
        for item in data:
            sleeper_id = str(item.get("player_id"))
            count = item.get("count", 0)
            our_id = model_data["sleeper_map"].get(sleeper_id)
            
            if our_id:
                card = await get_player_card(our_id, week)
                if card:
                    card["trending_count"] = count 
                    cards.append(card)
            
            if len(cards) >= limit: break
            
        return cards
    except: return []

# --- 5. ENDPOINTS ---
class PlayerRequest(BaseModel):
    player_name: str
    week: Optional[int] = None

class CompareRequest(BaseModel):
    player1_name: str
    player2_name: str
    week: Optional[int] = None

@app.get("/player/{player_id}")
async def get_player_by_id(player_id: str, week: Optional[int] = None):
    try:
        wk = week if week else model_data["current_nfl_week"]
        card = await get_player_card(player_id, wk)
        if not card: raise HTTPException(404, "Player not found")
        return card
    except Exception as e: raise HTTPException(500, str(e))

@app.get("/current_week")
async def get_current_week(): return {"week": model_data.get("current_nfl_week", 1)}

@app.get("/schedule/{week}")
async def get_schedule(week: int):
    try: 
        # Safety Check: If we forced Week 16 but DB only has up to Week 15, fallback to 15
        if not model_data["df_schedule"].is_empty():
            max_week = model_data["df_schedule"]["week"].max()
            if week > max_week:
                print(f"‚ö†Ô∏è Requested Week {week} not in DB (Max: {max_week}). Falling back.")
                week = max_week
                
        return model_data["df_schedule"].filter(pl.col("week") == week).to_dicts()
    except: return []

@app.get("/matchup/{week}/{home_team}/{away_team}")
async def get_matchup_rosters(week: int, home_team: str, away_team: str):
    try:
        home_cards = await get_team_roster_cards(home_team, week)
        away_cards = await get_team_roster_cards(away_team, week)
        return {"matchup": f"{away_team} @ {home_team}", "week": week, "home_roster": home_cards, "away_roster": away_cards}
    except Exception as e: raise HTTPException(status_code=500, detail="Failed to load matchup")

@app.post("/predict")
async def predict(req: PlayerRequest):
    try:
        match = model_data["df_profile"].filter(pl.col('player_name').str.to_lowercase() == req.player_name.lower())
        if match.is_empty(): raise HTTPException(404, "Player not found")
        pid = match.row(0, named=True)['player_id']
        wk = req.week if req.week else model_data["current_nfl_week"]
        return await get_player_card(pid, wk)
    except Exception as e: raise HTTPException(500, str(e))

@app.post("/compare")
async def compare(req: CompareRequest):
    wk = req.week if req.week else model_data["current_nfl_week"]
    res = []
    for name in [req.player1_name, req.player2_name]:
        try:
            match = model_data["df_profile"].filter(pl.col('player_name').str.to_lowercase() == name.lower())
            if not match.is_empty():
                pid = match.row(0, named=True)['player_id']
                res.append(await get_player_card(pid, wk))
            else: res.append({"error": f"Player {name} not found"})
        except: res.append({"error": "Lookup failed"})
    return {"week": wk, "comparison": res}

@app.get('/players/search')
async def search_players(q: str):
    if not q: return []
    try:
        expr = (
            pl.col('player_name').str.to_lowercase().str.contains(q.lower()) &
            (pl.col('position').is_in(['QB', 'RB', 'WR', 'TE']))
        )
        return model_data["df_profile"].filter(expr).select([
            'player_id', 'player_name', 'position', 'team_abbr', 'headshot', 'status'
        ]).head(20).to_dicts()
    except: return []

@app.get("/rankings/past/{week}")
async def get_trending_down(week: int):
    return await fetch_sleeper_trends("drop", limit=30, week=week)

@app.get("/rankings/future/{week}")
async def get_trending_up(week: int):
    return await fetch_sleeper_trends("add", limit=30, week=week)

@app.get("/player/history/{player_id}")
async def get_player_history(player_id: str):
    try:
        stats = model_data['df_player_stats'].filter(pl.col('player_id') == player_id).unique(subset=['week']).sort('week')
        player_snaps = model_data['df_snap_counts'].filter(pl.col('player_id') == player_id)
        if stats.is_empty(): return []

        history = []
        for row in stats.iter_rows(named=True):
            wk = row['week']
            snap_count, snap_pct = 0, 0.0
            s_row = player_snaps.filter(pl.col('week') == wk)
            if not s_row.is_empty():
                s_data = s_row.row(0, named=True)
                snap_count, snap_pct = int(s_data.get('offense_snaps', 0)), float(s_data.get('offense_pct', 0.0))

            p_yds = row.get('passing_yards') or 0
            r_yds = row.get('rushing_yards') or 0
            rec_yds = row.get('receiving_yards') or 0
            p_tds = row.get('passing_tds') or 0
            r_tds = row.get('rushing_tds') or 0
            rec_tds = row.get('receiving_tds') or 0
            receptions = int(row.get('receptions') or 0)
            targets = int(row.get('targets') or 0)
            
            # --- FIXED: Use correct column 'rush_attempts' ---
            carries = int(row.get('rush_attempts') or 0)

            pts = calculate_fantasy_points(row)

            history.append({
                "week": wk,
                "opponent": row.get('opponent_team') or "N/A",
                "points": round(float(pts), 2),
                "passing_yds": int(p_yds),
                "rushing_yds": int(r_yds),
                "receiving_yds": int(rec_yds),
                "touchdowns": int(p_tds + r_tds + rec_tds),
                "snap_count": snap_count,
                "snap_percentage": snap_pct,
                "receptions": receptions,
                "targets": targets,
                "carries": carries 
            })
        return history
    except Exception as e:
        print(f"History Error: {e}")
        return []

# --- WATCHLIST ---
def load_wl(): return json.load(open(WATCHLIST_FILE)) if os.path.exists(WATCHLIST_FILE) else []
@app.get('/watchlist')
async def get_watchlist():
    ids = load_wl()
    if not ids: return []
    return model_data["df_profile"].filter(pl.col("player_id").is_in(ids)).select(['player_id', 'player_name', 'team_abbr', 'position']).to_dicts()
@app.post('/watchlist')
async def add_watchlist(item: dict):
    ids = load_wl()
    if item['player_id'] not in ids:
        ids.append(item['player_id'])
        with open(WATCHLIST_FILE, 'w') as f: json.dump(ids, f)
    return ids
@app.delete('/watchlist/{player_id}')
async def remove_watchlist(player_id: str):
    ids = load_wl()
    if player_id in ids:
        ids.remove(player_id)
        with open(WATCHLIST_FILE, 'w') as f: json.dump(ids, f)
    return ids

if __name__ == '__main__':
    import uvicorn
    uvicorn.run("server:app", host="127.0.0.1", port=8000, reload=True)